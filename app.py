import streamlit as st
import pdfplumber
from openai import OpenAI
import os

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="å·¥ä¸šæœºå™¨äººè½¨è¿¹æ’è¡¥ - ç»¼è¿°ç”Ÿæˆå™¨",
    page_icon="ğŸ¤–",
    layout="wide"
)

# --- ä¾§è¾¹æ ï¼šè®¾ç½® ---
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")
    api_key = st.text_input("è¯·è¾“å…¥ API Key (OpenAI/DeepSeekç­‰)", type="password")
    base_url = st.text_input("Base URL (å¯é€‰)", value="https://api.openai.com/v1", help="å¦‚æœä½ ä½¿ç”¨çš„æ˜¯DeepSeekæˆ–ä¸­è½¬APIï¼Œè¯·ä¿®æ”¹æ­¤å¤„")
    model_name = st.text_input("æ¨¡å‹åç§°", value="gpt-4-turbo", help="å»ºè®®ä½¿ç”¨æ”¯æŒé•¿æ–‡æœ¬çš„æ¨¡å‹ï¼Œå¦‚ gpt-4-turbo æˆ– deepseek-chat")
    
    st.markdown("---")
    st.markdown("### å…³äºæœ¬å·¥å…·")
    st.info("æœ¬å·¥å…·ä¸“é—¨ç”¨äºç”Ÿæˆã€Šå·¥ä¸šæœºå™¨äººè½¨è¿¹æ’è¡¥æŠ€æœ¯ç ”ç©¶ã€‹ç»¼è¿°ã€‚åªéœ€æ‹–å…¥PDFï¼Œå³å¯æŒ‰æŒ‡å®šå­¦æœ¯æ ‡å‡†ç”ŸæˆæŠ¥å‘Šã€‚")

# --- æ ¸å¿ƒå‡½æ•°ï¼šæå–PDFæ–‡æœ¬ ---
def extract_text_from_pdfs(uploaded_files):
    combined_text = ""
    file_info = []
    
    progress_bar = st.progress(0)
    for i, file in enumerate(uploaded_files):
        try:
            with pdfplumber.open(file) as pdf:
                text = ""
                for page in pdf.pages:
                    text += page.extract_text() or ""
                # æˆªå–æ¯ç¯‡è®ºæ–‡çš„å‰5000å­—ï¼ˆé€šå¸¸åŒ…å«æ‘˜è¦ã€å¼•è¨€ã€ç»“è®ºå’Œæ ¸å¿ƒæ–¹æ³•ï¼‰ï¼Œé˜²æ­¢Tokenæº¢å‡º
                # å¦‚æœæ¨¡å‹æ”¯æŒæå¤§ä¸Šä¸‹æ–‡ï¼ˆå¦‚Kimi/Claude-200kï¼‰ï¼Œå¯ä»¥å»æ‰åˆ‡ç‰‡
                combined_text += f"\n--- Start of Paper: {file.name} ---\n{text[:8000]}\n--- End of Paper ---\n"
                file_info.append(file.name)
        except Exception as e:
            st.error(f"è¯»å–æ–‡ä»¶ {file.name} å¤±è´¥: {e}")
        progress_bar.progress((i + 1) / len(uploaded_files))
    
    return combined_text, file_info

# --- æ ¸å¿ƒå‡½æ•°ï¼šè°ƒç”¨LLMç”Ÿæˆç»¼è¿° ---
def generate_review(text_content, api_key, base_url, model):
    client = OpenAI(api_key=api_key, base_url=base_url)
    
    # è¿™é‡Œçš„Promptä¸¥æ ¼éµå¾ªäº†ä½ çš„æ‰€æœ‰è¦æ±‚
    system_prompt = """
    ä½ æ˜¯ä¸€ä½æœºå™¨äººé¢†åŸŸçš„èµ„æ·±å­¦æœ¯ä¸“å®¶ã€‚è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„å¤šç¯‡è®ºæ–‡å†…å®¹ï¼Œæ’°å†™ä¸€ç¯‡æœ‰å…³â€œå·¥ä¸šæœºå™¨äººè½¨è¿¹æ’è¡¥æŠ€æœ¯ç ”ç©¶â€çš„æ–‡çŒ®ç»¼è¿°ã€‚
    
    å¿…é¡»ä¸¥æ ¼éµå®ˆä»¥ä¸‹ã€ç»“æ„è¦æ±‚ã€‘ï¼š
    1. ç ”ç©¶èƒŒæ™¯: é˜è¿°è¯¥é¢†åŸŸçš„èµ·æºå’Œå‘å±•åŠ¨æœºã€‚
    2. ç ”ç©¶è„‰ç»œ: æŒ‰æ—¶é—´çº¿æ¢³ç†å…³é”®çªç ´(1980s-2024)ã€‚
    3. æ–¹æ³•åˆ†ç±»: å¯¹æ¶‰åŠçš„æ–¹æ³•è¿›è¡Œåˆ†ç±»ï¼Œå¹¶å¯¹æ¯”æ¯ç±»æ–¹æ³•çš„ä¼˜ç¼ºç‚¹ã€‚
    4. ç ”ç©¶ç©ºç™½: æŒ‡å‡ºå½“å‰æœªè§£å†³çš„3-5ä¸ªå…³é”®é—®é¢˜ã€‚
    5. æœªæ¥æ–¹å‘: åŸºäºå·²æœ‰ç ”ç©¶è¿›è¡Œåˆç†æ¨æµ‹ã€‚

    å¿…é¡»ä¸¥æ ¼éµå®ˆä»¥ä¸‹ã€å†™ä½œè¦æ±‚ã€‘ï¼š
    - å¼•ç”¨æ ¼å¼ï¼šæ¯ä¸ªè®ºç‚¹å¿…é¡»å¼•ç”¨å…·ä½“è®ºæ–‡ï¼Œæ ¼å¼ä¸º (First Author, Year)ã€‚
    - è¯­è¨€é£æ ¼ï¼šä½¿ç”¨å­¦æœ¯åŒ–è¯­è¨€ï¼Œå®¢è§‚ä¸­ç«‹ï¼Œé¿å…ä¸»è§‚è¯„ä»·ã€‚
    - äº‰è®®å¤„ç†ï¼šå¯¹æœ‰äº‰è®®çš„è§‚ç‚¹å‘ˆç°å¤šæ–¹ç«‹åœºã€‚
    - è¾“å‡ºæ ¼å¼ï¼šMarkdownã€‚
    - å…³é”®æœ¯è¯­é¦–æ¬¡å‡ºç°æ—¶è¯·åŠ ç²—ï¼ˆä¾‹å¦‚ï¼š**NURBSæ’è¡¥**ï¼‰ã€‚
    """

    user_prompt = f"""
    ä»¥ä¸‹æ˜¯ä¸Šä¼ çš„è®ºæ–‡å†…å®¹æ‘˜è¦é›†ï¼š
    {text_content}
    
    è¯·å¼€å§‹æ’°å†™ç»¼è¿°ã€‚
    """

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            stream=True 
        )
        return response
    except Exception as e:
        st.error(f"API è°ƒç”¨å¤±è´¥: {e}")
        return None

# --- ä¸»ç•Œé¢ UI ---
st.title("ğŸ“„ å·¥ä¸šæœºå™¨äººè½¨è¿¹æ’è¡¥ - æ™ºèƒ½ç»¼è¿°ç”Ÿæˆå™¨")
st.markdown("è¯·ç›´æ¥**æ‹–æ‹½**ç›¸å…³çš„ PDF è®ºæ–‡æ–‡ä»¶åˆ°ä¸‹æ–¹åŒºåŸŸã€‚")

uploaded_files = st.file_uploader("ä¸Šä¼ è®ºæ–‡ PDF (æ”¯æŒå¤šé€‰)", type="pdf", accept_multiple_files=True)

if uploaded_files and api_key:
    if st.button("ğŸš€ å¼€å§‹ç”Ÿæˆç»¼è¿°", type="primary"):
        with st.spinner('æ­£åœ¨è§£æ PDF å†…å®¹å¹¶æå–å…³é”®ä¿¡æ¯...'):
            # 1. æå–æ–‡æœ¬
            raw_text, files_list = extract_text_from_pdfs(uploaded_files)
            st.success(f"æˆåŠŸè§£æ {len(files_list)} ç¯‡è®ºæ–‡ï¼æ­£åœ¨è¯·æ±‚ AI æ’°å†™ç»¼è¿°...")
            
            # 2. ç”Ÿæˆç»¼è¿°ï¼ˆæµå¼è¾“å‡ºï¼‰
            output_placeholder = st.empty()
            full_response = ""
            
            response_stream = generate_review(raw_text, api_key, base_url, model_name)
            
            if response_stream:
                for chunk in response_stream:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        full_response += content
                        output_placeholder.markdown(full_response + "â–Œ") # æ¨¡æ‹Ÿæ‰“å­—æœºæ•ˆæœ
                
                output_placeholder.markdown(full_response) # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
                
                # 3. ä¸‹è½½æŒ‰é’®
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½ç»¼è¿° (Markdown)",
                    data=full_response,
                    file_name="Literature_Review_Interpolation.md",
                    mime="text/markdown"
                )
elif uploaded_files and not api_key:
    st.warning("è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ è¾“å…¥ API Key åå¼€å§‹ã€‚")
